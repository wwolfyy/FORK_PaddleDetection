{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune CDLA pretrained model for KR court decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running verify PaddlePaddle program ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0515 18:23:07.056653 2191296 program_interpreter.cc:212] New Executor is Running.\n",
      "W0515 18:23:07.056973 2191296 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.4, Runtime API Version: 11.8\n",
      "W0515 18:23:07.057626 2191296 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaddlePaddle works well on 1 GPU.\n",
      "PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n",
      "/bin/bash: /home/lstm/miniconda3/envs/pp261/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/home/lstm/github/PaddleDetection/tuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0515 18:23:07.307837 2191296 interpreter_util.cc:624] Standalone Executor is Used.\n"
     ]
    }
   ],
   "source": [
    "import subprocess, os, time, json\n",
    "import fitz\n",
    "import paddle\n",
    "paddle.utils.run_check()\n",
    "\n",
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 ../tools/eval.py -c ../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_train.yml -o weights=./trained_weights/output_20240503/best_model/model.pdparams\n"
     ]
    }
   ],
   "source": [
    "\n",
    "command = (\n",
    "    \"python3 ../tools/eval.py\",\n",
    "    \"-c ../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_train.yml\",\n",
    "    # \"--slim_config ../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_distill.yml\",\n",
    "    # \"-o weights=../output/best_model\",\n",
    "    \"-o weights=./trained_weights/output_20240503/best_model/model.pdparams\",\n",
    "    # \"use_gpu=true\",\n",
    "    # \"--use_vdl=True --vdl_log_dir=vdl_log\"\n",
    "    )\n",
    "command = \" \".join(command)\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test \n",
    "##### Strategy: use command line method to test trained weights; create inference model for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test prep (convert PDFs to images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pdf to image and save\n",
    "\n",
    "import fitz\n",
    "import os\n",
    "\n",
    "pdf_folder = './testdata/'\n",
    "# pdf_folder = './tuning/testdata/'\n",
    "\n",
    "for pdf_path in os.listdir(pdf_folder):\n",
    "\n",
    "    if not pdf_path.endswith('.pdf'):\n",
    "        continue\n",
    "\n",
    "    pdf_name = os.path.splitext(pdf_path)[0]\n",
    "    img_folder = os.path.join(pdf_folder, pdf_name)\n",
    "    if not os.path.isdir(img_folder):\n",
    "        os.mkdir(img_folder)\n",
    "\n",
    "    pdf_path = os.path.join(pdf_folder, pdf_path)\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        img_name = os.path.join(img_folder, f'{page_num}.png')\n",
    "        if not os.path.isfile(img_name):\n",
    "            page.get_pixmap().save(img_name)\n",
    "        else:\n",
    "            print(f\"{img_name} exists!\")\n",
    "\n",
    "    doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "configfile = \"../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_train.yml\"\n",
    "slim_configfile = \" ../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_distill.yml\"\n",
    "# opts = \"weights=./trained_weights/output_20240423/best_model/model.pdparams\"\n",
    "\n",
    "inference_datafolder = './testdata'\n",
    "testdoc_img_folder = 'image1'\n",
    "\n",
    "inference_outputfolder = './testoutput'\n",
    "testout_img_folder = 'image1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"config\": \"../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_train.yml\",\n",
      "    \"infer_dir\": \"./testdata/image1\",\n",
      "    \"infer_img\": null,\n",
      "    \"output_dir\": \"./testdata/image1\",\n",
      "    \"draw_threshold\": 0.5,\n",
      "    \"save_results\": false,\n",
      "    \"visualize\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    'config': configfile,\n",
    "    # 'slim_config': slim_configfile,\n",
    "    'infer_dir': f'{inference_datafolder}/{testdoc_img_folder}',\n",
    "    'infer_img': None,\n",
    "    'output_dir': f'{inference_datafolder}/{testout_img_folder}',\n",
    "    'draw_threshold': 0.5, # default\n",
    "    # 'use_vdl': True,\n",
    "    # 'vdl_log_dir': '/vdl_log_test',\n",
    "    'save_results': False,\n",
    "    # slice_infer, action='store_true',\n",
    "    # slice_size, nargs='+,\n",
    "    # overlap_ratio, nargs='+',\n",
    "    # combine_method: None,\n",
    "    # match_threshold: None,\n",
    "    # match_metric: None,\n",
    "    'visualize': True\n",
    "}\n",
    "\n",
    "print(json.dumps(args, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = 'testdata'\n",
    "# filelist = os.listdir(datapath)\n",
    "\n",
    "# def pdf2byte(filename):\n",
    "#     pdf = fitz.open(os.path.join(datapath, filename))\n",
    "#     for pg in range(pdf.pageCount):\n",
    "#         # convert pdf to image and store in local variable\n",
    "#         page = pdf[pg]\n",
    "#         pix = page.getPixmap()\n",
    "#         img_data = page.getPixmap().tobytes(\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 ../tools/infer.py -c ../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_train.yml --infer_dir=./testdata/JPEG_SAMPLE -o weights=./trained_weights/output_20240503/best_model/model.pdparams --draw_threshold=0.5 --save_results=true --visualize=True --output_dir=./testresults\n",
      "/bin/bash: /home/lstm/miniconda3/envs/pp261/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "W0515 19:07:35.222344 2235026 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.4, Runtime API Version: 11.8\n",
      "W0515 19:07:35.223192 2235026 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.\n",
      "[05/15 19:07:35] ppdet.utils.checkpoint INFO: Finish loading model weights: ./trained_weights/output_20240503/best_model/model.pdparams\n",
      "[05/15 19:07:35] train INFO: Found 2 inference images in total.\n",
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  5.31it/s]\n",
      "[05/15 19:07:36] ppdet.metrics.metrics INFO: The bbox result is saved to bbox.json.\n",
      "[05/15 19:07:36] ppdet.metrics.metrics INFO: The bbox result is saved to ./testresults/bbox.json and do not evaluate the mAP.\n",
      "[05/15 19:07:36] ppdet.engine INFO: Detection bbox results save in ./testresults/adobe_table_서울고등법원_2002노311_3.jpg\n",
      "[05/15 19:07:36] ppdet.engine INFO: Detection bbox results save in ./testresults/adobe_table_광주지법_2019구합10788_판결서_0.jpg\n"
     ]
    }
   ],
   "source": [
    "configfile = \"../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_train.yml\"\n",
    "slim_configfile = \"../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_distill.yml\"\n",
    "\n",
    "inference_datafolder = './testdata'\n",
    "testdoc_img_folder = 'JPEG_SAMPLE'\n",
    "weight2use = '20240503'\n",
    "output_dir = './testresults'\n",
    "\n",
    "command = (\n",
    "    \"python3 ../tools/infer.py\",\n",
    "    f\"-c {configfile}\",\n",
    "    # f\"--slim_config {slim_configfile}\",\n",
    "    f\"--infer_dir={inference_datafolder}/{testdoc_img_folder}\",\n",
    "    # f\"--infer_img={inference_datafolder}/{testdoc_img_folder}/0.png\",\n",
    "    f\"-o weights=./trained_weights/output_{weight2use}/best_model/model.pdparams\",\n",
    "    \"--draw_threshold=0.5\",\n",
    "    \"--save_results=true\",\n",
    "    \"--visualize=True\",\n",
    "    # \"use_gpu=true\",\n",
    "    # \"--use_vdl=True\",\n",
    "    # \"--vdl_log_dir=./vdl_log_test\",\n",
    "    f\"--output_dir={output_dir}\"\n",
    "    )\n",
    "\n",
    "command = \" \".join(command)\n",
    "print(command)\n",
    "\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy (use PaddleOCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model export (distilled model)\n",
    "https://github.com/PaddlePaddle/PaddleOCR/blob/release/2.7/ppstructure/docs/quickstart_en.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 ../tools/export_model.py -c ../configs/picodet/legacy_model/application/layout_analysis/krcase_layout_train.yml -o weights=./trained_weights/output_20240503/best_model/model.pdparams --output_dir=./exported_model/latest\n"
     ]
    }
   ],
   "source": [
    "model_outpath = './exported_model/latest'\n",
    "# model_outpath = './exported_model/krcase_layout_train'\n",
    "\n",
    "command = (\n",
    "    \"python3 ../tools/export_model.py\",\n",
    "    f\"-c {configfile}\",\n",
    "    # f\"--slim_config {slim_configfile}\",\n",
    "    f\"-o weights=./trained_weights/output_{weight2use}/best_model/model.pdparams\",\n",
    "    f\"--output_dir={model_outpath}\"\n",
    "    )\n",
    "command = \" \".join(command)\n",
    "print(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/lstm/miniconda3/envs/pp261/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "[05/15 20:04:15] ppdet.utils.checkpoint INFO: Finish loading model weights: ./trained_weights/output_20240503/best_model/model.pdparams\n",
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n",
      "[05/15 20:04:15] ppdet.engine INFO: Export inference config file to ./exported_model/latest/krcase_layout_train/infer_cfg.yml\n",
      "I0515 20:04:19.211127 2296309 program_interpreter.cc:212] New Executor is Running.\n",
      "[05/15 20:04:19] ppdet.engine INFO: Export model and saved in ./exported_model/latest/krcase_layout_train\n"
     ]
    }
   ],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model inference (distilled model)\n",
    "\n",
    "| Field | Description | Default |\n",
    "|-|-|-|  \n",
    "| output | result save path | ./output/table |\n",
    "| table_max_len | long side of the image resize in table structure model | 488 |\n",
    "| table_model_dir | Table structure model inference model path | None |\n",
    "| table_char_dict_path | The dictionary path of table structure model | ../ppocr/utils/dict/table_structure_dict.txt |\n",
    "| merge_no_span_structure | In the table recognition model, whether to merge '<td>' and '</td>' | False |\n",
    "| layout_model_dir | Layout analysis model inference model path | None |\n",
    "| layout_dict_path | The dictionary path of layout analysis model | ../ppocr/utils/dict/layout_publaynet_dict.txt |\n",
    "| layout_score_threshold | The box threshold path of layout analysis model | 0.5 |\n",
    "| layout_nms_threshold | The nms threshold path of layout analysis model | 0.5 |\n",
    "| kie_algorithm | kie model algorithm | LayoutXLM |\n",
    "| ser_model_dir | Ser model inference model path | None |\n",
    "| ser_dict_path | The dictionary path of Ser model | ../train_data/XFUND/class_list_xfun.txt |\n",
    "| mode | structure or kie | structure |\n",
    "| image_orientation | Whether to perform image orientation classification in forward | False |\n",
    "| layout | Whether to perform layout analysis in forward | True |\n",
    "| table | Whether to perform table recognition in forward | True |\n",
    "| ocr | Whether to perform ocr for non-table areas in layout analysis. When layout is False, it will be automatically set to False | True |\n",
    "| recovery | Whether to perform layout recovery in forward | False |\n",
    "| save_pdf | Whether to convert docx to pdf when recovery | False |\n",
    "| structure_version | Structure version, optional PP-structure and PP-structurev2 | PP-structure |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adobe_table_광주지법_2019구합10788_판결서_0.jpg', 'adobe_table_서울고등법원_2002노311_3.jpg']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from paddleocr import PPStructure,draw_structure_result,save_structure_res\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "inference_datafolder = './testdata/JPEG_SAMPLE'\n",
    "# testdoc_img_folder = 'CONVERTED_JPEG'\n",
    "\n",
    "inference_outputfolder = './testresults_deployment/latest'\n",
    "# testout_img_folder = 'CONVERTED_JPEG'\n",
    "\n",
    "font_path = '../NotoSansKR-Regular.otf' # PaddleOCR\n",
    "\n",
    "imgs = os.listdir(f\"{inference_datafolder}\")\n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/05/15 20:05:04] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir=None, cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='/home/lstm/.paddleocr/whl/det/ch/Multilingual_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm=None, kwargs={'OCR_det_language': 'ml', 'OCR_rec_language': 'korean'}, label_list=['0', '180'], lang='ch', layout=True, layout_dict_path='/home/lstm/github/PaddleOCR/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt', layout_model_dir='./exported_model/latest/krcase_layout_train', layout_nms_threshold=0.3, layout_score_threshold=0.4, max_batch_size=10, max_text_length=25, merge_no_span_structure=False, min_subgraph_size=15, mode='structure', ocr=False, ocr_order_method=None, ocr_version='PP-OCRv4', output='./testresults_deployment/latest', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/home/lstm/github/PaddleOCR/ppocr/utils/dict/korean_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='/home/lstm/.paddleocr/whl/rec/korean/korean_PP-OCRv4_rec_infer', recovery=False, return_word_box=False, save_crop_res=False, save_log_path='./log_output/', save_pdf=False, savefile=False, scales=[8, 16, 32], ser_dict_path=None, ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=False, table_algorithm='TableAttn', table_char_dict_path='/home/lstm/github/PaddleOCR/ppocr/utils/dict/table_structure_dict_ch.txt', table_max_len=None, table_model_dir='/home/lstm/.paddleocr/whl/table/ch_ppstructure_mobile_v2.0_SLANet_infer', total_process_num=1, type='ocr', use_angle_cls=False, use_dilation=False, use_gpu=True, use_mlu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "(InvalidArgument) The input of Op(Conv) should be a 4-D or 5-D Tensor. But received: input's dimension is -1, input's shape is [].\n  [Hint: Expected in_dims.size() == 4 || in_dims.size() == 5 == true, but received in_dims.size() == 4 || in_dims.size() == 5:0 != true:1.] (at /paddle/paddle/phi/kernels/cpu/conv_util.h:137)\n  [operator < fused_conv2d_add_act > error]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minference_datafolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# display(img)\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mlayout_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m save_structure_res(result, inference_outputfolder, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(imgpath)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     57\u001b[0m im_show \u001b[38;5;241m=\u001b[39m draw_structure_result(img, result,font_path\u001b[38;5;241m=\u001b[39mfont_path)\n",
      "File \u001b[0;32m~/github/PaddleOCR/paddleocr.py:788\u001b[0m, in \u001b[0;36mPPStructure.__call__\u001b[0;34m(self, img, return_ocr_result_in_table, img_idx, alpha_color)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, return_ocr_result_in_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, img_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, alpha_color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m)):\n\u001b[1;32m    787\u001b[0m     img \u001b[38;5;241m=\u001b[39m check_img(img, alpha_color)\n\u001b[0;32m--> 788\u001b[0m     res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_ocr_result_in_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/github/PaddleOCR/ppstructure/predict_system.py:115\u001b[0m, in \u001b[0;36mStructureSystem.__call__\u001b[0;34m(self, img, return_ocr_result_in_table, img_idx)\u001b[0m\n\u001b[1;32m    113\u001b[0m ori_im \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_predictor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     layout_res, elapse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayout_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     time_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m elapse\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/github/PaddleOCR/ppstructure/layout/predict_layout.py:86\u001b[0m, in \u001b[0;36mLayoutPredictor.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     83\u001b[0m starttime \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_tensor\u001b[38;5;241m.\u001b[39mcopy_from_cpu(img)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m np_score_list, np_boxes_list \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m     89\u001b[0m output_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mget_output_names()\n",
      "\u001b[0;31mValueError\u001b[0m: (InvalidArgument) The input of Op(Conv) should be a 4-D or 5-D Tensor. But received: input's dimension is -1, input's shape is [].\n  [Hint: Expected in_dims.size() == 4 || in_dims.size() == 5 == true, but received in_dims.size() == 4 || in_dims.size() == 5:0 != true:1.] (at /paddle/paddle/phi/kernels/cpu/conv_util.h:137)\n  [operator < fused_conv2d_add_act > error]"
     ]
    }
   ],
   "source": [
    "\n",
    "# get layout\n",
    "\n",
    "run_OCR = False #\n",
    "# kr_dict_path = '../ppocr/utils/dict/korean_dict.txt'\n",
    "\n",
    "layout_engine = PPStructure(\n",
    "    # lang='korean',\n",
    "    output=inference_outputfolder,\n",
    "    merge_no_span_structure=False,\n",
    "    # [PaddleOCR] ocr_version\n",
    "    # [PaddleOCR]use_onnx\n",
    "    det_model_dir=None,\n",
    "    # det_algorithm #[DB]\n",
    "    rec_model_dir=None,\n",
    "    # [PaddleOCR] rec_algorithm #[\"CRNN\", \"SVTR_LCNet\"]\n",
    "    # rec_char_dict_path=kr_dict_path, # Path(__file__).parent / rec_model_config[\"dict_path\"]\n",
    "    # [PaddleOCR] cls_model_dir\n",
    "    # [PaddleOCR] rec_image_shape # if ocr_version in [\"PP-OCRv3\", \"PP-OCRv4\"]\n",
    "    table_model_dir=None,\n",
    "    table_max_len=None, # 488\n",
    "    table_char_dict_path=None,\n",
    "    layout_model_dir=\"./exported_model/latest/krcase_layout_train\", #None\n",
    "    # layout_model_dir=\"./krcase_layout_train\", #None\n",
    "    # layout_model_dir=\"./exported_model/picodet_lcnet_x1_0_fgd_layout_infer\",\n",
    "    # layout_model_dir=\"./exported_model/krcase_layout_train_20240503\",\n",
    "    layout_dict_path=None, # use <layout_dict_path> ? (dict should be in exported model)\n",
    "    layout_score_threshold=0.4, # 0.5\n",
    "    layout_nms_threshold= 0.3, # 0.5\n",
    "    kie_algorithm=None, # LayoutXLM\n",
    "    ser_model_dir=None,\n",
    "    ser_dict_path=None, #../train_data/XFUND/class_list_xfun.txt\n",
    "    mode=\"structure\", # ocr\n",
    "    image_orientation=False,\n",
    "    layout=True,\n",
    "    table=False,\n",
    "    ocr=run_OCR,\n",
    "    recovery=False,\n",
    "    save_pdf=False,\n",
    "    structure_version=\"PP-StructureV2\", #\"PP-Structure\"\n",
    "    show_log=True,\n",
    "    kwargs={\"OCR_det_language\":'ml', \"OCR_rec_language\":'korean'}\n",
    "    )\n",
    "\n",
    "for imgpath in imgs:\n",
    "\n",
    "    # imgpath = 'adobe_table_서울고등법원_2002노311_10.jpg'\n",
    "    # imgpath = 'scan_fn_부산지법_2018나55364_판결서_2.jpg'\n",
    "    # imgpath = 'scan_서울중앙지법_2014가합38499_판결서_1.jpg'\n",
    "    # imgpath = 'adobe_table_광주지법_2019구합10788_판결서_1.jpg'\n",
    "    # imgpath = 'adobe_특허법원 2017허8459_8.jpg'\n",
    "\n",
    "    img = cv2.imread(f\"{inference_datafolder}/{imgpath}\")\n",
    "    # display(img)\n",
    "    result = layout_engine(img)\n",
    "    save_structure_res(result, inference_outputfolder, os.path.basename(imgpath).split('.')[0])\n",
    "\n",
    "    im_show = draw_structure_result(img, result,font_path=font_path)\n",
    "    imgbyte = Image.fromarray(im_show)\n",
    "\n",
    "    # create output folder if not existing\n",
    "    if not os.path.isdir(f\"{inference_outputfolder}\"):\n",
    "        os.mkdir(f\"{inference_outputfolder}\")\n",
    "\n",
    "\n",
    "    # show left half only (if no OCR is run)\n",
    "    if not run_OCR:\n",
    "        height, width = im_show.shape[:2]\n",
    "        mid_x = width // 2\n",
    "\n",
    "        # Crop left side\n",
    "        box = (0, 0, mid_x, height)\n",
    "        img_left = imgbyte.crop(box)\n",
    "\n",
    "        img_left.save(f\"{inference_outputfolder}/{imgpath}\")\n",
    "\n",
    "        # display image\n",
    "        display(img_left)\n",
    "    else:\n",
    "        imgbyte.save(f\"{inference_outputfolder}/{imgpath}\")\n",
    "\n",
    "        # display image\n",
    "        display(imgbyte)\n",
    "\n",
    "    # if imgpath == imgs[0]:\n",
    "    #     break\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # usin predict_system.py\n",
    "# from\n",
    "\n",
    "# python3 predict_system.py --layout_model_dir=inference/picodet_lcnet_x1_0_fgd_layout_cdla_infer \\\n",
    "#                           --image_dir=../DATA/sample_data/판례/png/image61_0.png \\\n",
    "#                           --output=../output \\\n",
    "#                           --table=false \\\n",
    "#                           --ocr=false \\\n",
    "#                           --vis_font_path=../NotoSansKR-Regular.otf \\\n",
    "#                           --layout_dict_path ../ppocr/utils/dict/layout_dict/layout_cdla_dict.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp261",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
